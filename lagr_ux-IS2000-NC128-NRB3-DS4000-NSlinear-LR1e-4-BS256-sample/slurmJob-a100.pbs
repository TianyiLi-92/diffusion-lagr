#!/bin/bash
#SBATCH -p std
#SBATCH --time 06:00:00      # format: HH:MM:SS
##SBATCH -w a100-2           # ask for specific host
#SBATCH -N 1                 # xxx node
#SBATCH --ntasks-per-node=16 # xxx core per node
#SBATCH --gres=gpu:a100:4    # xxx gpus per node
#SBATCH --mem=256000         # memory per node out of xxx MB
#SBATCH --job-name=lagr-sample
##SBATCH --mail-type=ALL
##SBATCH --mail-user=<user_email>

echo "CUDA_VISIBLE_DEVICES=$CUDA_VISIBLE_DEVICES"

source ~/.bashrc
conda activate diffusion-lagr

export OPENAI_LOGDIR="/mnt/petaStor/li/Job/diffusion-lagr/lagr_ux-IS2000-NC128-NRB3-DS4000-NSlinear-LR1e-4-BS256-sample"

SAMPLE_FLAGS="--num_samples 4096 --batch_size 64 --model_path /mnt/petaStor/li/Job/diffusion-lagr/lagr_ux-IS2000-NC128-NRB3-DS4000-NSlinear-LR1e-4-BS256-train/ema_0.9999_100000.pt"
MODEL_FLAGS="--dims 1 --image_size 2000 --in_channels 1 --num_channels 128 --num_res_blocks 3 --attention_resolutions 250,125 --channel_mult 1,1,2,3,4"
DIFFUSION_FLAGS="--diffusion_steps 4000 --noise_schedule linear"

mpiexec -n 4 python ../scripts/turb_sample.py $SAMPLE_FLAGS $MODEL_FLAGS $DIFFUSION_FLAGS
